{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f9820d-21c4-4ab9-bdea-234dcd7de20e",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec5be513-d77c-44f6-9f6c-c4ec6013755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScript that contains details about the neural network model used for the DQN Agent\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script that contains details about the neural network model used for the DQN Agent\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e2910-6ae7-4302-a804-053f83e3960a",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fac485-3219-47b0-9fe1-1d7727003e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269879b-42c3-4ed7-a13f-332a59d4faed",
   "metadata": {},
   "source": [
    "Get the file storing the configurations and read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27865c70-7d91-4418-8c12-28004fcfaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "  \n",
    "configur = ConfigParser()\n",
    "import builtins\n",
    "configur.read(builtins.current_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9882b-5b55-42cb-9a86-56c8ab9d1d49",
   "metadata": {},
   "source": [
    "Read the layer parameter from the sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea768c6-c560-40bc-98e9-422663f37c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1=int(configur.get('architecture','layer1'))\n",
    "layer2=int(configur.get('architecture','layer2'))\n",
    "\n",
    "# configur.read('config.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8f906-2e63-48ea-a0b2-cb26b41ed2dc",
   "metadata": {},
   "source": [
    "Initialise the model with two hidden layers and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1dad535-8683-45fe-936b-4fdcb57e8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Class that defines the architecture of the neural network for the DQN agent\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, lr=1e-3):\n",
    "        super(DQNNet, self).__init__()\n",
    "        self.dense1 = nn.Linear(input_size, layer1)\n",
    "        self.dense2 = nn.Linear(layer1, layer2)\n",
    "        self.dense3 = nn.Linear(layer2, output_size)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "    # Define the forward pass of the network.\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = F.relu(self.dense2(x))\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "    # Save the model.\n",
    "    def saveModel(self, filename):\n",
    "        \"\"\"\n",
    "        Function to save model parameters\n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "        filename: str\n",
    "            Location of the file where the model is to be saved\n",
    "\n",
    "        Returns\n",
    "        ---\n",
    "        none\n",
    "        \"\"\"\n",
    "\n",
    "        torch.save(self.state_dict(), filename)\n",
    "    #Load the saved model from the file.\n",
    "    def loadModel(self, filename, device):\n",
    "        \"\"\"\n",
    "        Function to load model parameters\n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "        filename: str\n",
    "            Location of the file from where the model is to be loaded\n",
    "        device:\n",
    "            Device in use - CPU or GPU\n",
    "\n",
    "        Returns\n",
    "        ---\n",
    "        none\n",
    "        \"\"\"\n",
    "\n",
    "        # map_location is required to ensure that a model that is trained on GPU can be run even on CPU\n",
    "        self.load_state_dict(torch.load(filename, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da354926-b285-46f7-86a1-eca332584c87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8618b8a-5798-4985-b576-1672bfb08ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2358e36c-aec0-480e-bfd7-00e5e23b4d64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ac11f85-70ec-4605-99c6-63c2de0e9f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e2e947-e3ba-4a23-b772-00a06bf6e34e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb6273-9d77-4fa4-a12a-577f8438aa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d22675-a8c1-4f7f-8147-55103cf54745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
